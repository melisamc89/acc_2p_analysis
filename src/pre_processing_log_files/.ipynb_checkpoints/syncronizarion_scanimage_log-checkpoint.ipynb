{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f936dd05-e49a-4aef-a325-13ac1c02ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation \n",
    "import numpy as np\n",
    "import base64\n",
    "import struct\n",
    "from cobs import cobs\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.signal\n",
    "from scipy.io import savemat\n",
    "import rawpy\n",
    "import os\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "from ScanImageTiffReader import  ScanImageTiffReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f826d0d2-482b-4841-8de3-75cb914cb53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ScanImageTiffHeader(file_path):\n",
    "\n",
    "    '''\n",
    "    Reads header description information of ScanImageTiff File\n",
    "    input: (str) tiff file path\n",
    "    output: (list) Dictionary and list containing I2C events information and frame timestamps \n",
    "    \n",
    "    '''\n",
    "    frameTs = []\n",
    "    i2c_timestamp = []\n",
    "    i2c_values = []\n",
    "    i2c_frameN = []\n",
    "\n",
    "    with ScanImageTiffReader(file_path) as reader:\n",
    "        time = reader.shape()[0]\n",
    "        for frame in range(time):\n",
    "            x = reader.description(frame)\n",
    "            description = x.split('\\n')\n",
    "            frameTs.append(float(description[3].split('=')[1]))\n",
    "            i2c= description[14].split('=')\n",
    "            if len(i2c[1])>3:\n",
    "                y = i2c[1].split('{{')[1].split(']}')\n",
    "                if len(y)==1:\n",
    "                    i2c_timestamp.append(float(y[events].split(',')[0]))\n",
    "                    i2c_values.append(int(y[events].split('[')[1]))\n",
    "                    i2c_frameN.append(frame)\n",
    "                else: \n",
    "                    i2c_timestamp.append(float(y[0].split(',')[0]))\n",
    "                    i2c_values.append(int(y[0].split('[')[1].split(',')[0]))\n",
    "                    i2c_frameN.append(frame)\n",
    "                    for events in range(1,len(y)-1):\n",
    "                        i2c_timestamp.append(float(y[events].split(',')[0].split('{')[1]))\n",
    "                        i2c_values.append(int(y[events].split('[')[1].split(',')[0]))\n",
    "                        i2c_frameN.append(frame)\n",
    "                        \n",
    "    I2C = {\"ts\":i2c_timestamp, \"val\":i2c_values, \"frameNum\":i2c_frameN}\n",
    "    return I2C, frameTs\n",
    "\n",
    "\n",
    "def unpack_data_packet(dp,DataPacketStruct,DataPacket):\n",
    "    s = struct.unpack(DataPacketStruct, dp)\n",
    "    up = DataPacket(type=s[0], size=s[1], crc16=s[2], packetID=s[3], us_start=s[4], us_end=s[5],\n",
    "                    analog=s[6:14], states=s[14:22], digitalIn=s[22], digitalOut=s[23], padding=None)\n",
    "    return up\n",
    "\n",
    "def count_lines(fp):\n",
    "    # function to count the packet number\n",
    "    def _make_gen(reader):\n",
    "        b = reader(2**16)\n",
    "        while b:\n",
    "            yield b\n",
    "            b = reader(2**16)\n",
    "    with open(fp, 'rb') as f:\n",
    "        count = sum(buf.count(b'\\n') for buf in _make_gen(f.raw.read))\n",
    "    return count\n",
    "\n",
    "\n",
    "def create_bp_structure(bp):\n",
    "    # Format package\n",
    "    DataPacketDesc = {'type': 'B',\n",
    "                      'size': 'B',\n",
    "                      'crc16': 'H',\n",
    "                      'packetID': 'I',\n",
    "                      'us_start': 'I',\n",
    "                      'us_end': 'I',\n",
    "                      'analog': '8H',\n",
    "                      'states': '8l',\n",
    "                      'digitalIn': 'H',\n",
    "                      'digitalOut': 'B',\n",
    "                      'padding': 'x'}\n",
    "\n",
    "    DataPacket = namedtuple('DataPacket', DataPacketDesc.keys())\n",
    "    DataPacketStruct = '<' + ''.join(DataPacketDesc.values())\n",
    "    DataPacketSize = struct.calcsize(DataPacketStruct)\n",
    "\n",
    "    # package with non-digital data\n",
    "    dtype_no_digital = [\n",
    "        ('type', np.uint8),\n",
    "        ('size', np.uint8),\n",
    "        ('crc16', np.uint16),\n",
    "        ('packetID', np.uint32),\n",
    "        ('us_start', np.uint32),\n",
    "        ('us_end', np.uint32),\n",
    "        ('analog', np.uint16, (8, )),\n",
    "        ('states', np.uint32, (8, ))]\n",
    "\n",
    "    # DigitalIn and DigitalOut\n",
    "    dtype_w_digital = dtype_no_digital + [('digital_in', np.uint16, (16, )), ('digital_out', np.uint8, (8, ))]\n",
    "\n",
    "    # Creating array with all the data (differenciation digital/non digital)\n",
    "    np_DataPacketType_noDigital = np.dtype(dtype_no_digital)\n",
    "    np_DataPacketType_withDigital = np.dtype(dtype_w_digital)\n",
    "    # Unpack the data as done on the teensy commander code\n",
    "    num_lines = count_lines(bp)\n",
    "    log_duration = num_lines/1000/60\n",
    "\n",
    "    # Decode and create new dataset\n",
    "    data = np.zeros(num_lines, dtype=np_DataPacketType_withDigital)\n",
    "    non_digital_names = list(np_DataPacketType_noDigital.names)\n",
    "\n",
    "    with open(bp, 'rb') as bf:\n",
    "        for nline, line in enumerate(tqdm(bf, total=num_lines)):\n",
    "            bl = cobs.decode(base64.b64decode(line[:-1])[:-1])\n",
    "            dp = unpack_data_packet(bl,DataPacketStruct,DataPacket)\n",
    "\n",
    "            data[non_digital_names][nline] = np.frombuffer(bl[:-4], dtype=np_DataPacketType_noDigital)\n",
    "            digital_arr = np.frombuffer(bl[-4:], dtype=np.uint8)\n",
    "            data[nline]['digital_in'] = np.hstack([np.unpackbits(digital_arr[1]), np.unpackbits(digital_arr[0])])\n",
    "            data[nline]['digital_out'] = np.unpackbits(np.array(digital_arr[2], dtype=np.uint8))\n",
    "        #Check for packetID jumps\n",
    "    jumps = np.unique(np.diff(data['packetID']))\n",
    "    decoded = {\"analog\":data['analog'], \"digitalIn\":data['digital_in'], \"digitalOut\":data['digital_out'], \"startTS\":data['us_start'], \"transmitTS\":data['us_end'], \"longVar\":data['states'], \"packetNums\":data['packetID']}\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac23249-9bdc-468e-9b85-e7f092b0f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Define scan image path\n",
    "scan_image_path = '/home/melisamc/Documentos/acc_2p_analysis/data/'\n",
    "scan_file = '20220308_Nike_audseq_00001.tif'\n",
    "### Define log file path\n",
    "log_file_path = '/home/melisamc/Documentos/acc_2p_analysis/logfiles/'\n",
    "log_file = '20221201-102828_264.b64'\n",
    "### get IC2 events\n",
    "[I2C, frameTs] = read_ScanImageTiffHeader(scan_image_path + scan_file)\n",
    "### get decoded log file information\n",
    "decoded = create_bp_structure(log_file_path + log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede43a09-c5a0-4b98-9094-c2bbab675f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path_dec = '/home/melisamc/Documentos/acc_2p_analysis/logfiles_decoded/'\n",
    "savemat(log_file_path_dec + '20221201-102828_264.mat', decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e29a07b-ec46-4e2e-9cce-0ade9991697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "packet = decoded\n",
    "def read_digitals(digitalIn,labels):\n",
    "    nChan = digitalIn.shape[1]\n",
    "    onset = []\n",
    "    offset = []\n",
    "\n",
    "    for chan in range(nChan):\n",
    "        diffChan = np.diff(digitalIn[:,chan])\n",
    "        onset.append(np.where(diffChan==1)[0]+1)\n",
    "        offset.append(np.where(diffChan==-1)[0])\n",
    "\n",
    "    digIn = {'onset':onset,'offset':offset,'labels':labels}\n",
    "    return digIn\n",
    "\n",
    "def polarity_index(digIn):\n",
    "    #### We need to check polarity, we can change the method later\n",
    "    nChan = len(digIn['onset'])\n",
    "    pol_index = np.zeros((nChan,))\n",
    "    \n",
    "    for n in range(nChan):\n",
    "        nOn = len(digIn['onset'][n])\n",
    "        nOff = len(digIn['offset'][n])\n",
    "        nevents = min(nOn,nOff)\n",
    "        \n",
    "        if nevents !=0:\n",
    "            medianFor = np.median(digIn['offset'][n][0:nevents]-digIn['onset'][n][0:nevents])\n",
    "            medianBack = np.median(digIn['onset'][n][1:nevents]-digIn['offset'][n][0:nevents-1])\n",
    "            if medianBack < medianFor:\n",
    "                pol_index[n] = 1\n",
    "                \n",
    "    force_pol_index = np.ones((nChan,))\n",
    "    force_pol_index[2]= 0\n",
    "    force_pol_index[3]= 0\n",
    "    force_pol_index[6]= 0\n",
    "    force_pol_index[7]= 0\n",
    "    pol_index = pol_index * force_pol_index\n",
    "\n",
    "    return pol_index\n",
    "\n",
    "def change_polarity(digIn,polarity):\n",
    "    \n",
    "    new_digIn_onset = []\n",
    "    new_digIn_offset = []\n",
    "    nChan = len(digIn['onset'])\n",
    "    for n in range(nChan):\n",
    "        if polarity[n] == 1:\n",
    "            new_digIn_onset.append(digIn['offset'][n])\n",
    "            new_digIn_offset.append(digIn['onset'][n])\n",
    "        else:\n",
    "            new_digIn_onset.append(digIn['onset'][n])\n",
    "            new_digIn_offset.append(digIn['offset'][n])\n",
    "\n",
    "    digIn['onset'] = new_digIn_onset\n",
    "    digIn['offset'] = new_digIn_offset\n",
    "    \n",
    "    return digIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8903831c-3b7b-466b-9d9d-0a886c1ea352",
   "metadata": {},
   "outputs": [],
   "source": [
    "digitalIn = packet['digitalIn'].astype(int)\n",
    "digitalIn = np.flip(digitalIn,axis =1)\n",
    "digitalOut = packet['digitalOut'].astype(int)\n",
    "digitalOut = np.flip(digitalOut,axis =1)\n",
    "\n",
    "###Pay attention because labels will change, this is under development\n",
    "### Read digital In and Out\n",
    "labelsIn = ['empty','empty','wheelA','wheelB','wheelC','IR_camera','scanner',\n",
    "             'sound','???','reward_zone','environment1','environment2','environment3_broken',\n",
    "             'tunnel1','tunnel2','environment3']\n",
    "labelsOut = ['valve','empty','IR_LED_sync','empty','barcode','IR_LED','lick','empty']\n",
    "digIn = read_digitals(digitalIn, labelsIn)\n",
    "digOut = read_digitals(digitalOut,labelsOut)\n",
    "\n",
    "### Check channel polarity (inverted or non inverted channels)\n",
    "polarity = polarity_index(digIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38d61f5-1bda-4884-b2a8-f884ad864c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65f2e0e0-6ade-4f85-abd1-d3e1255780ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trials definition\n",
    "# A trial will be define as one if there is a reward zone onset in between\n",
    "\n",
    "# Check first onset to be correct, that means being before the first offset\n",
    "# Define environment 1 start times in env1St\n",
    "first_onset = digIn['onset'][10][0]\n",
    "first_offset = digIn['offset'][10][0]\n",
    "\n",
    "digIn = change_polarity(digIn,polarity)\n",
    "\n",
    "first_onset = digIn['onset'][10][0]\n",
    "first_offset = digIn['offset'][10][0]\n",
    "\n",
    "if first_onset > first_offset:\n",
    "    env1St = np.zeros((len(digIn['onset'][10])+1,)).astype(int)\n",
    "    env1St[0] = 1\n",
    "    env1St[1:]= digIn['onset'][10]\n",
    "else:\n",
    "    env1St = digIn['onset'][10]\n",
    "    \n",
    "env2St = digIn['onset'][11]    \n",
    "env3St = digIn['onset'][15]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d77d7e9-7f66-47d7-b93a-7dc7d4d3b360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23166"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digIn['onset'][10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38bee660-3053-4bc2-9874-9739e7834981",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sort events and id events\n",
    "n_events = len(env1St) + len(env2St) + len(env3St)\n",
    "events_id = np.zeros((n_events,))\n",
    "events_time = np.zeros((n_events,))\n",
    "events_id[0:len(env1St)] = 1\n",
    "events_time[0:len(env1St)] = env1St\n",
    "events_id[len(env1St):len(env1St) + len(env2St)] = 2\n",
    "events_time[len(env1St):len(env1St) + len(env2St)] = env2St\n",
    "events_id[len(env1St) + len(env2St):] = 3\n",
    "events_time[len(env1St) + len(env2St):] = env3St\n",
    "sorted_index = np.argsort(events_time)\n",
    "sorted_events_id = events_id[sorted_index].astype(int)\n",
    "sorted_events_time = events_time[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81f96b-2213-4983-b494-71538e157bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b130139-a0f0-487b-b931-67c033f42c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### make sure that there is a reward zone between all trial start\n",
    "rewZonSt = digIn['onset'][9]\n",
    "bins_edge = np.zeros((n_events+1,))\n",
    "bins_edge[:-1] = sorted_events_time\n",
    "bins_edge[-1] = np.max(sorted_events_time)+100000\n",
    "env_with_RewZone = np.where(np.histogram(rewZonSt,bins_edge)[0])[0]\n",
    "\n",
    "###redefine trial onset, Id and number of trials\n",
    "trialOn = bins_edge[env_with_RewZone][0:11].astype(int)\n",
    "trialId = sorted_events_id[env_with_RewZone][0:11].astype(int)\n",
    "nTrials = 11#len(trialSt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "335246e6-c45a-42a4-9634-9e663e6b96e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  23166,   67044,  293577,  507349,  549415,  607919,  848080,\n",
       "        943346, 1057283, 1094172, 1134334])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trialOn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7c16f2e6-388c-4750-8380-2b224daecf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we construct the trial info matrix\n",
    "# % 1 env onset\n",
    "# % 2 env id\n",
    "# % 3 sound onset\n",
    "# % 4 sound offset\n",
    "# % 5 tunnel1 onset\n",
    "# % 6 rewZone onset\n",
    "# % 7 reward delivery\n",
    "# % 8 tunnel2 onset\n",
    "# % 9 tunnel2 offset\n",
    "# % 10 trial duration\n",
    "\n",
    "trialInfoLables = []\n",
    "\n",
    "InfoEntrySize = 10\n",
    "### Environment Start\n",
    "trialInfo = np.zeros((nTrials,InfoEntrySize))\n",
    "trialInfo[:,0] = trialOn[0:nTrials]\n",
    "trialInfoLables.append('environmentStart')\n",
    "### Environment ID\n",
    "trialInfo[:,1] = trialId[0:nTrials]\n",
    "trialInfoLables.append('environmentId')\n",
    "### Tunnel 1 Onset \n",
    "tun1St = digIn['onset'][13][0:nTrials]\n",
    "bins_edge = np.zeros((nTrials+1,))\n",
    "bins_edge[:-1] = trialOn\n",
    "bins_edge[-1] = np.max(trialOn)+100000\n",
    "tun1St = tun1St[np.where(tun1St > bins_edge[0])]\n",
    "[n_tun_in_trial,new_bins] = np.histogram(tun1St,bins_edge)\n",
    "tun1St_ = np.zeros((nTrials,))\n",
    "tun1St_[np.where(n_tun_in_trial)[0]] = tun1St\n",
    "index_with_tunnel = np.where(n_tun_in_trial > 0)\n",
    "index_with_one_tunnel = np.unique(index_with_tunnel)\n",
    "trialInfo[index_with_one_tunnel,4] = tun1St_[index_with_one_tunnel] \n",
    "trialInfoLables.append('tunnel1Start')\n",
    "### Sound Onset\n",
    "SoundOnset = digIn['onset'][7][0:7]\n",
    "temp = np.sort(trialInfo[:,[0,4]].flatten())\n",
    "bins_edge = np.zeros((len(temp)+1,))\n",
    "bins_edge[:-1] = temp\n",
    "bins_edge[-1] = temp[-1] + 10000000000\n",
    "[n_sounds_in_trial,new_bins] = np.histogram(SoundOnset,bins_edge)\n",
    "trial_with_sound = (np.where(n_sounds_in_trial)[0]/2).astype(int)\n",
    "#trial_with_sound_index = np.where(n_sounds_in_trial)[0]\n",
    "trialInfo[trial_with_sound,2] = SoundOnset\n",
    "trialInfoLables.append('SoundOnset')\n",
    "\n",
    "### Sound Offset\n",
    "SoundOffset = digIn['offset'][7][0:7]\n",
    "temp = np.sort(trialInfo[:,[0,4]].flatten())\n",
    "bins_edge = np.zeros((len(temp)+1,))\n",
    "bins_edge[:-1] = temp\n",
    "bins_edge[-1] = temp[-1] + 10000000000\n",
    "[n_sounds_in_trial,new_bins] = np.histogram(SoundOffset,bins_edge)\n",
    "trial_with_sound = (np.where(n_sounds_in_trial)[0]/2).astype(int)\n",
    "#trial_with_sound_index = np.where(n_sounds_in_trial)[0]\n",
    "trialInfo[trial_with_sound,3] = SoundOffset\n",
    "trialInfoLables.append('SoundOffset')\n",
    "### RewardZone1\n",
    "rewZSt = digIn['onset'][9][0:nTrials]\n",
    "bins_edge = np.zeros((nTrials+1,))\n",
    "bins_edge[:-1] = trialOn\n",
    "bins_edge[-1] = np.max(trialOn)+100000\n",
    "\n",
    "rewZSt = rewZSt[np.where(rewZSt > bins_edge[0])]\n",
    "[n_tun_in_trial,new_bins] = np.histogram(rewZSt,bins_edge)\n",
    "rewZSt_ = np.zeros((nTrials,))\n",
    "rewZSt_[np.where(n_tun_in_trial)[0]] = rewZSt\n",
    "index_with_tunnel = np.where(n_tun_in_trial > 0)\n",
    "index_with_one_tunnel = np.unique(index_with_tunnel)\n",
    "trialInfo[index_with_one_tunnel,5] = rewZSt_[index_with_one_tunnel] \n",
    "trialInfoLables.append('RewardZoneStart')\n",
    "### Tunnel 2 Onset \n",
    "tun2St = digIn['onset'][13][0:nTrials]\n",
    "bins_edge = np.zeros((nTrials+1,))\n",
    "bins_edge[:-1] = trialOn\n",
    "bins_edge[-1] = np.max(trialOn)+100000\n",
    "tun2St = tun2St[np.where(tun2St > bins_edge[0])]\n",
    "[n_tun_in_trial,new_bins] = np.histogram(tun2St,bins_edge)\n",
    "tun2St_ = np.zeros((nTrials,))\n",
    "tun2St_[np.where(n_tun_in_trial)[0]] = tun1St\n",
    "index_with_tunnel = np.where(n_tun_in_trial > 0)\n",
    "index_with_one_tunnel = np.unique(index_with_tunnel)\n",
    "trialInfo[index_with_one_tunnel,7] = tun2St_[index_with_one_tunnel] \n",
    "trialInfoLables.append('tunnel2Start')\n",
    "### Tunnel 2 Offset \n",
    "tun2Off = digIn['offset'][13][0:nTrials]\n",
    "bins_edge = np.zeros((nTrials+1,))\n",
    "bins_edge[:-1] = trialInfo[:,7]\n",
    "bins_edge[-1] = np.max(trialInfo[:,7])+100000\n",
    "tun2Off = tun2Off[np.where(tun2Off > bins_edge[0])]\n",
    "[n_tun_in_trial,new_bins] = np.histogram(tun2Off,bins_edge)\n",
    "tun2Off_ = np.zeros((nTrials,))\n",
    "tun2Off_[np.where(n_tun_in_trial)[0]] = tun2Off\n",
    "index_with_tunnel = np.where(n_tun_in_trial > 0)\n",
    "index_with_one_tunnel = np.unique(index_with_tunnel)\n",
    "trialInfo[index_with_one_tunnel,4] = tun2St_[index_with_one_tunnel] \n",
    "trialInfoLables.append('tunnel2End')\n",
    "### Reward delivery (1srt)\n",
    "rewDel = digOut['onset'][0][0:7]\n",
    "temp = np.sort(trialInfo[:,[5,7]].flatten())\n",
    "bins_edge = np.zeros((len(temp)+1,))\n",
    "bins_edge[:-1] = temp\n",
    "bins_edge[-1] = temp[-1] + 10000000000\n",
    "[n_rew_in_trial,new_bins] = np.histogram(rewDel,bins_edge)\n",
    "trial_with_rew = (np.where(n_rew_in_trial)[0]/2).astype(int)\n",
    "\n",
    "rewDel_ = np.zeros((nTrials,))\n",
    "rewDel_[trial_with_reward] = rewDel[trial_with_rew]\n",
    "index_with_rew = np.where(n_rew_in_trial > 0)\n",
    "index_with_one_rew = np.unique(index_with_rew)\n",
    "\n",
    "trialInfo[trial_with_rew,6] = rewDel[trial_with_rew]\n",
    "trialInfoLables.append('rewardDelivery')\n",
    "trialInfo[:,9] = trialInfo[:,8] - trialInfo[:,0]\n",
    "trialInfoLables.append('trialDuration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcdb7a9-503a-407d-b88f-9ad7164c26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now we convert to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0a82bb1d-8824-4528-9995-e07e731ad87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6812b4c2-c51f-4e7a-987b-192f67776c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "06eda830-34c5-49e2-aed5-2db134cbe42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2a408203-934d-4535-b42e-056637668ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "44770064-0ea7-4e0e-97b7-975afacff15e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b8ce2c8a-0ca8-4805-9668-4231e3e7f78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e09f18fe-42ee-4e6e-9b99-7cc0ad802dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5bccb37b-199d-4ca2-946a-24b9259bf389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20221201-102828_264\n",
      "Number of frames: (22986,)\n",
      "Mean Scanner time per frame: 0.03339563007004569\n"
     ]
    }
   ],
   "source": [
    "name='20221201-102828_264'\n",
    "print(name)\n",
    "path=os.path.join(log_file_path, name +'_decoded'+'.mat')\n",
    "savemat(path, decoded)\n",
    "frameTs = np.array(frameTs)\n",
    "print('Number of frames:', frameTs.shape)\n",
    "print('Mean Scanner time per frame:', np.mean(np.diff(frameTs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26872bd5-9035-4d3a-80e1-54953e4fe2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Offset is: 293577 ms \n",
      "Offset is: 60512678 frames \n",
      "Number of frames is:  6\n",
      "Instantaneous Sampling rate is:  206122.0\n"
     ]
    }
   ],
   "source": [
    "### compute offset assuming scanner time starts in 0\n",
    "x = decoded['digitalIn'][:,0]\n",
    "print(x[1])\n",
    "x_diff = np.diff(x)\n",
    "positions = np.where(x_diff == 1)[0]+1\n",
    "what_we_want = x_diff[positions]\n",
    "\n",
    "sampling_rate_scanner = np.mean(np.diff(positions))\n",
    "offset_frames = round(positions[0]*sampling_rate_scanner/1000)\n",
    "\n",
    "print('Offset is: ' + f'{positions[0]}' + ' ms ' )\n",
    "print('Offset is: ' + f'{offset_frames}' + ' frames ')\n",
    "\n",
    "print('Number of frames is: ', len(what_we_want))\n",
    "print('Instantaneous Sampling rate is: ', sampling_rate_scanner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "925f227c-ec34-444c-af52-57b4029d95a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analog': array([[1863,    6, 1788, ..., 2448, 2482, 2480],\n",
       "        [1856,    5, 1780, ..., 2447, 2485, 2488],\n",
       "        [1858,    4, 1788, ..., 2446, 2483, 2483],\n",
       "        ...,\n",
       "        [1852,    7, 1795, ..., 2434, 2479, 2485],\n",
       "        [1853,    8, 1783, ..., 2441, 2483, 2484],\n",
       "        [1854,    7, 1726, ..., 2437, 2481, 2468]], dtype=uint16),\n",
       " 'digitalIn': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint16),\n",
       " 'digitalOut': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0]], dtype=uint8),\n",
       " 'startTS': array([1169320555, 1169321555, 1169322555, ..., 1739426211, 1739427211,\n",
       "        1739428211], dtype=uint32),\n",
       " 'transmitTS': array([1169320740, 1169321740, 1169322740, ..., 1739426396, 1739427396,\n",
       "        1739428396], dtype=uint32),\n",
       " 'longVar': array([[1940302,  118358,       5, ...,       0,       0,     186],\n",
       "        [1940302,  118358,       4, ...,       0,       0,     186],\n",
       "        [1940302,  118358,       6, ...,       0,       0,     185],\n",
       "        ...,\n",
       "        [ 853326,   52052,       4, ...,       0,       0,     185],\n",
       "        [ 853326,   52052,       7, ...,       0,       0,     185],\n",
       "        [ 853326,   52052,       5, ...,       0,       0,     185]],\n",
       "       dtype=uint32),\n",
       " 'packetNums': array([65589828, 65589829, 65589830, ..., 67352385, 67352386, 67352387],\n",
       "       dtype=uint32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c256a25-21ce-48a4-a99d-fa7f8bf92489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
